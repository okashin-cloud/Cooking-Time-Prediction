{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random as rn\n",
    "import re\n",
    "from collections import deque\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from gensim.models import KeyedVectors, word2vec\n",
    "from IPython.display import HTML, SVG\n",
    "from keras import backend as K\n",
    "from keras import (constraints, initializers, layers, models, optimizers,\n",
    "                   regularizers)\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import (LSTM, Activation, Average, Bidirectional, Dense,\n",
    "                          Dropout, Embedding, Flatten, Input, Lambda, Masking,\n",
    "                          Permute, Reshape, merge, multiply)\n",
    "from keras.models import Model, Sequential, load_model, model_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.673983Z",
     "start_time": "2020-10-25T07:15:07.103Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.676223Z",
     "start_time": "2020-10-25T07:15:07.107Z"
    }
   },
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(2))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.678056Z",
     "start_time": "2020-10-25T07:15:07.111Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "LSTM_UNITS = 64\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT = 0.1\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.679745Z",
     "start_time": "2020-10-25T07:15:07.116Z"
    }
   },
   "outputs": [],
   "source": [
    "train_recipe_size = 10000\n",
    "dev_recipe_size = 5000\n",
    "test_recipe_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.680720Z",
     "start_time": "2020-10-25T07:15:07.119Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_path = '/hoge/hoge.model'\n",
    "word2vec_matrix = word2vec.Word2Vec.load(word2vec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.681715Z",
     "start_time": "2020-10-25T07:15:07.123Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.python.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.preprocessing import sequence\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "#シードの固定\n",
    "def seed(seed):\n",
    "    config = tf.compat.v1.ConfigProto()###\n",
    "    config.gpu_options.allow_growth = True###\n",
    "    sess = tf.compat.v1.Session(config=config)###\n",
    "    tf.compat.v1.keras.backend.set_session(sess)###\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    np.random.seed(seed)\n",
    "    rn.seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads = 1, inter_op_parallelism_threads = 1)\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    session = tf.compat.v1.Session(graph = tf.compat.v1.get_default_graph(), config = session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時間呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.682680Z",
     "start_time": "2020-10-25T07:15:07.128Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = '/hoge/hoge.csv'\n",
    "dev_path = '/hoge/hoge.csv'\n",
    "test_path = '/hoge/hoge.csv'\n",
    "df_id_process_time_turn_divide_time_train = pd.read_csv(train_path)\n",
    "df_id_process_time_turn_divide_time_dev = pd.read_csv(dev_path)\n",
    "df_id_process_time_turn_divide_time_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 時間をlogに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.683516Z",
     "start_time": "2020-10-25T07:15:07.133Z"
    }
   },
   "outputs": [],
   "source": [
    "def realtime_to_logtime(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.684506Z",
     "start_time": "2020-10-25T07:15:07.137Z"
    }
   },
   "outputs": [],
   "source": [
    "#レシピごとの調理時間にまとめる\n",
    "def process_log_time(df):\n",
    "    log_time_list = []\n",
    "    id_ = 0\n",
    "    for index,row in df.iterrows():\n",
    "        if row['id'] != id_:\n",
    "            id_ = row['id']\n",
    "            log_time_list.append(realtime_to_logtime(row['time']))\n",
    "    return log_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.685402Z",
     "start_time": "2020-10-25T07:15:07.141Z"
    }
   },
   "outputs": [],
   "source": [
    "log_time_list_train = process_log_time(df_id_process_time_turn_divide_time_train)\n",
    "log_time_array_train = np.array(log_time_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.686421Z",
     "start_time": "2020-10-25T07:15:07.144Z"
    }
   },
   "outputs": [],
   "source": [
    "log_time_list_dev = process_log_time(df_id_process_time_turn_divide_time_dev)\n",
    "log_time_array_dev = np.array(log_time_list_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.687537Z",
     "start_time": "2020-10-25T07:15:07.147Z"
    }
   },
   "outputs": [],
   "source": [
    "log_time_list_test = process_log_time(df_id_process_time_turn_divide_time_test)\n",
    "log_time_array_test = np.array(log_time_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピの最大手順をリストにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.688524Z",
     "start_time": "2020-10-25T07:15:07.154Z"
    }
   },
   "outputs": [],
   "source": [
    "train_max_turn_path = '/hoge/hoge.csv'\n",
    "dev_max_turn_path = '/hoge/hoge.csv'\n",
    "test_max_turn_path = '/hoge/hoge.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.689512Z",
     "start_time": "2020-10-25T07:15:07.158Z"
    }
   },
   "outputs": [],
   "source": [
    "df_max_turn_train= pd.read_csv(train_max_turn_path, sep=\",\")\n",
    "\n",
    "max_turn_train_list = df_max_turn_train.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.690439Z",
     "start_time": "2020-10-25T07:15:07.161Z"
    }
   },
   "outputs": [],
   "source": [
    "df_max_turn_dev= pd.read_csv(dev_max_turn_path, sep=\",\")\n",
    "\n",
    "max_turn_dev_list = df_max_turn_dev.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.691409Z",
     "start_time": "2020-10-25T07:15:07.165Z"
    }
   },
   "outputs": [],
   "source": [
    "df_max_turn_test= pd.read_csv(test_max_turn_path, sep=\",\")\n",
    "\n",
    "max_turn_test_list = df_max_turn_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.692253Z",
     "start_time": "2020-10-25T07:15:07.169Z"
    }
   },
   "outputs": [],
   "source": [
    "del df_max_turn_train\n",
    "del df_max_turn_dev\n",
    "del df_max_turn_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単語にインデックスを割り当てる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.693222Z",
     "start_time": "2020-10-25T07:15:07.173Z"
    }
   },
   "outputs": [],
   "source": [
    "word_list = word2vec_matrix.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.694147Z",
     "start_time": "2020-10-25T07:15:07.178Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_dic = {}\n",
    "#indexは１からスタートさせる\n",
    "#index0をpadding用とする\n",
    "index = 1\n",
    "for word in word_list:\n",
    "    if word not in word_index_dic:\n",
    "        word_index_dic[word] = index\n",
    "        index += 1\n",
    "#unkのindexは最後とする\n",
    "word_index_dic['<unk>'] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mecabしたレシピを対応づける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.695108Z",
     "start_time": "2020-10-25T07:15:07.182Z"
    }
   },
   "outputs": [],
   "source": [
    "train_mecab_path = '/hoge/hoge.csv'\n",
    "dev_mecab_path = '/hoge/hoge.csv'\n",
    "test_mecab_path = '/hoge/hoge.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.696002Z",
     "start_time": "2020-10-25T07:15:07.185Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(train_mecab_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    mecab_procedure_words_train_list = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.697016Z",
     "start_time": "2020-10-25T07:15:07.189Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(dev_mecab_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    mecab_procedure_words_dev_list = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.697845Z",
     "start_time": "2020-10-25T07:15:07.193Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(test_mecab_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    mecab_procedure_words_test_list = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.698847Z",
     "start_time": "2020-10-25T07:15:07.196Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_words_index_list(mecab_procedure_words_list,max_turn_list):\n",
    "    process_index_list = []\n",
    "    d = deque(max_turn_list)\n",
    "    #最後のpopが処理されるためにappend\n",
    "    d.append(0)\n",
    "    #divideは各手順の最大手順数\n",
    "    max_turn = d.popleft()\n",
    "\n",
    "    for procedure_words_list in mecab_procedure_words_list:\n",
    "        procedure_index_list = []\n",
    "  \n",
    "        for word in procedure_words_list:\n",
    "            procedure_index_list.append(word_index_dic[word])\n",
    "\n",
    "        process_index_list.append(procedure_index_list)\n",
    "    return process_index_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.699701Z",
     "start_time": "2020-10-25T07:15:07.200Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_train_list = get_words_index_list(mecab_procedure_words_train_list,max_turn_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.700697Z",
     "start_time": "2020-10-25T07:15:07.204Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_dev_list = get_words_index_list(mecab_procedure_words_dev_list,max_turn_dev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.701871Z",
     "start_time": "2020-10-25T07:15:07.208Z"
    }
   },
   "outputs": [],
   "source": [
    "#testデータが元のままでunkをunkとしていなかった\n",
    "processes_test_list = []\n",
    "for process in mecab_procedure_words_test_list:\n",
    "    process_test_list = []\n",
    "    for word in process:\n",
    "        if word in word_list:\n",
    "            process_test_list.append(word)\n",
    "        else:\n",
    "            process_test_list.append('<unk>')\n",
    "    processes_test_list.append(process_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.702923Z",
     "start_time": "2020-10-25T07:15:07.214Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_test_list = get_words_index_list(processes_test_list,max_turn_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainだけベクトルを持つembedding_matrixの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.705306Z",
     "start_time": "2020-10-25T07:15:07.218Z"
    }
   },
   "outputs": [],
   "source": [
    "#valueからkeyを抽出\n",
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.706200Z",
     "start_time": "2020-10-25T07:15:07.223Z"
    }
   },
   "outputs": [],
   "source": [
    "size = len(word2vec_matrix[word_list[0]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.707083Z",
     "start_time": "2020-10-25T07:15:07.226Z"
    }
   },
   "outputs": [],
   "source": [
    "unk_list = np.zeros(size).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.708043Z",
     "start_time": "2020-10-25T07:15:07.230Z"
    }
   },
   "outputs": [],
   "source": [
    "#train,dev,test全ての単語を使用\n",
    "#trainに対応しないdev,testの単語は全て０ベクトルとなる\n",
    "#<unk>も０ベクトルとする\n",
    "size = len(word2vec_matrix[word_list[0]].tolist())\n",
    "embedding_matrix = np.zeros((len(word_index_dic)+1, size))\n",
    "used_index = []\n",
    "for procedure_index in word_index_train_list:\n",
    "    for index in procedure_index:\n",
    "        if index not in used_index:\n",
    "            word = get_keys_from_value(word_index_dic,index)[0]\n",
    "            if word == '<unk>':\n",
    "                embedding_matrix[index] = unk_list\n",
    "            else:\n",
    "                embedding_matrix[index] = word2vec_matrix[word].tolist()\n",
    "            used_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.709018Z",
     "start_time": "2020-10-25T07:15:07.233Z"
    }
   },
   "outputs": [],
   "source": [
    "del used_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大長を見つける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.710119Z",
     "start_time": "2020-10-25T07:15:07.237Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len_train = max([len(i) for i in word_index_train_list])\n",
    "max_len_dev = max([len(i) for i in word_index_dev_list])\n",
    "max_len_test = max([len(i) for i in word_index_test_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.711381Z",
     "start_time": "2020-10-25T07:15:07.241Z"
    }
   },
   "outputs": [],
   "source": [
    "if max_len_train > max_len_test and max_len_train > max_len_dev:\n",
    "    max_len = max_len_train\n",
    "elif max_len_dev > max_len_train and max_len_dev > max_len_test:\n",
    "        max_len = max_len_dev\n",
    "else:\n",
    "    max_len = max_len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.712305Z",
     "start_time": "2020-10-25T07:15:07.244Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(max_len_train,max_len_dev,max_len_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最大手順を探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.713479Z",
     "start_time": "2020-10-25T07:15:07.249Z"
    }
   },
   "outputs": [],
   "source": [
    "turn_train_list = [i[0] for i in max_turn_train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.714539Z",
     "start_time": "2020-10-25T07:15:07.252Z"
    }
   },
   "outputs": [],
   "source": [
    "turn_dev_list = [i[0] for i in max_turn_dev_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.715543Z",
     "start_time": "2020-10-25T07:15:07.256Z"
    }
   },
   "outputs": [],
   "source": [
    "turn_test_list = [i[0] for i in max_turn_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.716601Z",
     "start_time": "2020-10-25T07:15:07.259Z"
    }
   },
   "outputs": [],
   "source": [
    "max_turn = int(max(max(turn_train_list),max(turn_dev_list),max(turn_test_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.717653Z",
     "start_time": "2020-10-25T07:15:07.279Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パディング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語数のパディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.718673Z",
     "start_time": "2020-10-25T07:15:07.283Z"
    }
   },
   "outputs": [],
   "source": [
    "index_for_padding=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.719639Z",
     "start_time": "2020-10-25T07:15:07.299Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_index_list(num):\n",
    "    return [index_for_padding] * num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.720570Z",
     "start_time": "2020-10-25T07:15:07.303Z"
    }
   },
   "outputs": [],
   "source": [
    "copy_index_train_list = copy.deepcopy(word_index_train_list)\n",
    "\n",
    "for index,word_index_list in enumerate(copy_index_train_list):\n",
    "    pad_num = max_len - len(word_index_list)\n",
    "    word_index_train_list[index].extend(padding_index_list(pad_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.721683Z",
     "start_time": "2020-10-25T07:15:07.307Z"
    }
   },
   "outputs": [],
   "source": [
    "copy_index_dev_list = copy.deepcopy(word_index_dev_list)\n",
    "\n",
    "for index,word_index_list in enumerate(copy_index_dev_list):\n",
    "    pad_num = max_len - len(word_index_list)\n",
    "    word_index_dev_list[index].extend(padding_index_list(pad_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.722824Z",
     "start_time": "2020-10-25T07:15:07.310Z"
    }
   },
   "outputs": [],
   "source": [
    "del copy_index_train_list\n",
    "del copy_index_dev_list\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語数のpaddingを表すone-hot-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.723783Z",
     "start_time": "2020-10-25T07:15:07.314Z"
    }
   },
   "outputs": [],
   "source": [
    "row_train = len(word_index_train_list[0])\n",
    "row_dev = len(word_index_dev_list[0])\n",
    "\n",
    "column = 1\n",
    "\n",
    "batch_train = train_recipe_size\n",
    "batch_dev = dev_recipe_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.724666Z",
     "start_time": "2020-10-25T07:15:07.317Z"
    }
   },
   "outputs": [],
   "source": [
    "#(barch,row,column)のlistを0で初期化\n",
    "paded_one_hot_vector_train_list = [[[[False] * column for i in range(row_train)] for j in range(max_turn)] for k in range(batch_train)]\n",
    "# word_len_train_list = [len(i) for i in mecab_procedure_words_train_list]\n",
    "\n",
    "paded_one_hot_vector_dev_list = [[[[False] * column for i in range(row_dev)] for j in range(max_turn)] for k in range(batch_dev)]\n",
    "# word_len_dev_list = [len(i) for i in mecab_procedure_words_dev_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.725783Z",
     "start_time": "2020-10-25T07:15:07.321Z"
    }
   },
   "outputs": [],
   "source": [
    "def recipe_words_len(word_list,max_turn_list):\n",
    "    recipe_words_len_list = []\n",
    "    index_ = 0\n",
    "    for max_turn in max_turn_list:\n",
    "        max_turn = int(max_turn[0])\n",
    "        process_words_len_list = [len(i) for i in word_list[index_:index_+max_turn]]\n",
    "        recipe_words_len_list.append(process_words_len_list)\n",
    "    return recipe_words_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.726903Z",
     "start_time": "2020-10-25T07:15:07.324Z"
    }
   },
   "outputs": [],
   "source": [
    "word_len_train_list = recipe_words_len(mecab_procedure_words_train_list,max_turn_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.727959Z",
     "start_time": "2020-10-25T07:15:07.328Z"
    }
   },
   "outputs": [],
   "source": [
    "word_len_dev_list = recipe_words_len(mecab_procedure_words_dev_list,max_turn_dev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.728989Z",
     "start_time": "2020-10-25T07:15:07.332Z"
    }
   },
   "outputs": [],
   "source": [
    "del mecab_procedure_words_train_list\n",
    "del mecab_procedure_words_dev_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.730027Z",
     "start_time": "2020-10-25T07:15:07.335Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_procedure(paded_list,word_len_list):\n",
    "    for batch,process_words_len_list in enumerate(word_len_list):\n",
    "        for index,word_len in enumerate(process_words_len_list):#手順数を入れるべき\n",
    "            for i in range(word_len):\n",
    "                paded_list[batch][index][i] = [True] * column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.731121Z",
     "start_time": "2020-10-25T07:15:07.339Z"
    }
   },
   "outputs": [],
   "source": [
    "# paded_one_hot_vector_train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.732066Z",
     "start_time": "2020-10-25T07:15:07.342Z"
    }
   },
   "outputs": [],
   "source": [
    "#procedureのmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.733163Z",
     "start_time": "2020-10-25T07:15:07.346Z"
    }
   },
   "outputs": [],
   "source": [
    "padding_procedure(paded_one_hot_vector_train_list,word_len_train_list[:train_recipe_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.734078Z",
     "start_time": "2020-10-25T07:15:07.349Z"
    }
   },
   "outputs": [],
   "source": [
    "padding_procedure(paded_one_hot_vector_dev_list,word_len_dev_list[:dev_recipe_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手順数のパディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.735021Z",
     "start_time": "2020-10-25T07:15:07.354Z"
    }
   },
   "outputs": [],
   "source": [
    "index_for_turn = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.735977Z",
     "start_time": "2020-10-25T07:15:07.357Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_index_turn_list(num):\n",
    "    return [[index_for_turn] * max_len for i in range(max_turn - num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.736923Z",
     "start_time": "2020-10-25T07:15:07.361Z"
    }
   },
   "outputs": [],
   "source": [
    "def padding_max_turn(word_index_list,max_turn_list):\n",
    "    now_index = 0\n",
    "    process_padding_index_list = []\n",
    "    copy_index_list = copy.deepcopy(word_index_list)\n",
    "    for max_turn in max_turn_list:\n",
    "        max_ = int(max_turn[0])\n",
    "        procedure_padding_index_list = copy_index_list[now_index:now_index+max_]\n",
    "        procedure_padding_index_list.extend(padding_index_turn_list(max_))\n",
    "        process_padding_index_list.append(procedure_padding_index_list)   \n",
    "        now_index += max_\n",
    "    return process_padding_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.737785Z",
     "start_time": "2020-10-25T07:15:07.364Z"
    }
   },
   "outputs": [],
   "source": [
    "#(レシピ数，手順数，単語数(index))\n",
    "process_padding_index_train_list = padding_max_turn(word_index_train_list,max_turn_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.738768Z",
     "start_time": "2020-10-25T07:15:07.369Z"
    }
   },
   "outputs": [],
   "source": [
    "process_padding_index_dev_list = padding_max_turn(word_index_dev_list,max_turn_dev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.739652Z",
     "start_time": "2020-10-25T07:15:07.375Z"
    }
   },
   "outputs": [],
   "source": [
    "del word_index_train_list\n",
    "del word_index_dev_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手順数のパディングを表すflagリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.740572Z",
     "start_time": "2020-10-25T07:15:07.379Z"
    }
   },
   "outputs": [],
   "source": [
    "row_turn_train = len(process_padding_index_train_list[0])\n",
    "row_turn_dev = len(process_padding_index_dev_list[0])\n",
    "\n",
    "column = 1\n",
    "\n",
    "batch_turn_train = len(process_padding_index_train_list)\n",
    "batch_turn_dev = len(process_padding_index_dev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.741583Z",
     "start_time": "2020-10-25T07:15:07.383Z"
    }
   },
   "outputs": [],
   "source": [
    "#(barch,row,column)のlistを0で初期化\n",
    "paded_flag_train_list = [[[False] * column for i in range(row_turn_train)] for j in range(batch_turn_train)]\n",
    "# word_len_train_list = [len(i) for i in mecab_process_words_train_list]\n",
    "\n",
    "paded_flag_dev_list = [[[False] * column for i in range(row_turn_dev)] for j in range(batch_turn_dev)]\n",
    "# word_len_dev_list = [len(i) for i in mecab_process_words_dev_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.742520Z",
     "start_time": "2020-10-25T07:15:07.386Z"
    }
   },
   "outputs": [],
   "source": [
    "def flag_list(paded_flag_list,max_turn_list):\n",
    "    for index,max_turn in enumerate(max_turn_list):\n",
    "        max_ = int(max_turn[0])\n",
    "        for i in range(max_):\n",
    "            paded_flag_list[index][i] = [True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.743459Z",
     "start_time": "2020-10-25T07:15:07.390Z"
    }
   },
   "outputs": [],
   "source": [
    "#processのmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.744397Z",
     "start_time": "2020-10-25T07:15:07.394Z"
    }
   },
   "outputs": [],
   "source": [
    "flag_list(paded_flag_train_list,max_turn_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.745307Z",
     "start_time": "2020-10-25T07:15:07.397Z"
    }
   },
   "outputs": [],
   "source": [
    "flag_list(paded_flag_dev_list,max_turn_dev_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.746213Z",
     "start_time": "2020-10-25T07:15:07.402Z"
    }
   },
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.747199Z",
     "start_time": "2020-10-25T07:15:07.406Z"
    }
   },
   "outputs": [],
   "source": [
    "class Recipe_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data, procedure_mask, process_mask, label, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.procedure_mask = procedure_mask\n",
    "        self.process_mask = process_mask\n",
    "        self.data_num = len(data)\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]),\\\n",
    "                    torch.tensor(self.process_mask[idx]),\\\n",
    "                    torch.tensor(self.procedure_mask[idx]),\\\n",
    "                    torch.tensor(self.label[idx],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.748088Z",
     "start_time": "2020-10-25T07:15:07.410Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = Recipe_Dataset(process_padding_index_train_list[:train_recipe_size],\n",
    "                               paded_one_hot_vector_train_list[:train_recipe_size],\n",
    "                               paded_flag_train_list[:train_recipe_size],\n",
    "                               log_time_array_train[:train_recipe_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.748924Z",
     "start_time": "2020-10-25T07:15:07.414Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dev = Recipe_Dataset(process_padding_index_dev_list[:dev_recipe_size],\n",
    "                               paded_one_hot_vector_dev_list[:dev_recipe_size],\n",
    "                               paded_flag_dev_list[:dev_recipe_size],\n",
    "                               log_time_array_dev[:dev_recipe_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.749880Z",
     "start_time": "2020-10-25T07:15:07.418Z"
    }
   },
   "outputs": [],
   "source": [
    "del process_padding_index_train_list\n",
    "del paded_one_hot_vector_train_list\n",
    "del paded_flag_train_list\n",
    "#del log_time_array_train\n",
    "\n",
    "del process_padding_index_dev_list\n",
    "del paded_one_hot_vector_dev_list\n",
    "del paded_flag_dev_list\n",
    "# del log_time_array_dev\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.750825Z",
     "start_time": "2020-10-25T07:15:07.424Z"
    }
   },
   "outputs": [],
   "source": [
    "class ProcedureAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, word_att_size, procedure_size, word_size, epsilon, dropout):        \n",
    "        super(ProcedureAttention, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        # Bidirectional procedure-level RNN\n",
    "        self.procedure_rnn = nn.LSTM(\n",
    "            emb_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.word_att_size = word_att_size\n",
    "        self.linear_ = nn.Linear(2 * hidden_size, 2 * word_att_size)\n",
    "        nn.init.xavier_uniform_(self.linear_.weight)\n",
    "        self.tanh_ = nn.Tanh()\n",
    "        self.softmax_ = nn.Softmax(dim=1)\n",
    "        self.u_a = nn.Parameter(torch.Tensor(2 * hidden_size, 1))\n",
    "        nn.init.xavier_uniform_(self.u_a)\n",
    "        \n",
    "        self.procedure_size = procedure_size  # 28\n",
    "        self.word_size = word_size  # 112\n",
    "        self.emb_size = emb_size  # 200\n",
    "        self.epsilon = epsilon  # 1e-7\n",
    "\n",
    "    def init_embeddings(self, weights):\n",
    "        self.embeddings.weight = nn.Parameter(torch.from_numpy(weights))\n",
    "\n",
    "        # トレーニング中，重みを更新させない\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, procedure, procedure_mask):\n",
    "#         print(self.u_a)\n",
    "#         print(self.linear_.weight)\n",
    "        batch_size = procedure.size()[0]  # 16(最後は１６じゃない時がある)\n",
    "\n",
    "        # procedure_mask:(16,28,112,1)->(16*28,112,1)\n",
    "\n",
    "        procedure_mask = procedure_mask.view(\n",
    "            batch_size*self.procedure_size, self.word_size, 1)\n",
    "\n",
    "        word_vector = self.embeddings(procedure).float()\n",
    "\n",
    "        # procedure:(16,28,112,200)->(16*28,112,200)\n",
    "        word_vector = word_vector.view(\n",
    "            batch_size*self.procedure_size, self.word_size, self.emb_size)\n",
    "        \n",
    "        word_vector = self.dropout(word_vector)\n",
    "\n",
    "        rnn_out, _ = self.procedure_rnn(word_vector)\n",
    "\n",
    "        h = self.tanh_(self.linear_(rnn_out))  # h = tanh(Wx+y)\n",
    "        dot = torch.matmul(h, self.u_a)\n",
    "        exp_ = torch.exp(dot)\n",
    "\n",
    "        # masking\n",
    "        # (16*28,112,1)*(16*28,112,1)->(16*28,112,1)\n",
    "        exp_ = exp_ * procedure_mask\n",
    "\n",
    "        exp_sum = torch.sum(exp_, dim=1)  # (16*28,1)\n",
    "        exp_sum += self.epsilon\n",
    "\n",
    "        x_dim = exp_sum.size()[0]\n",
    "        y_dim = exp_sum.size()[1]\n",
    "        exp_sum_add_dim = exp_sum.view(x_dim, y_dim, 1)  # (16*28,1,1)\n",
    " \n",
    "        alpha = torch.div(exp_, exp_sum_add_dim)\n",
    "        procedure_vector = torch.mul(rnn_out, alpha).sum(dim=1)  # (16*28,128)\n",
    " \n",
    "        # reshape(16*28,128)->(16,28,128)\n",
    "        procedure_vector_reshape = procedure_vector.view(\n",
    "            batch_size, self.procedure_size, -1)\n",
    "     \n",
    "        return procedure_vector_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.751751Z",
     "start_time": "2020-10-25T07:15:07.429Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ProcessAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, word_att_size, procedure_size, word_size, epsilon, dropout):\n",
    "        super(ProcessAttention, self).__init__()\n",
    "        self.procedure_attention = ProcedureAttention(\n",
    "            vocab_size, emb_size, hidden_size, word_att_size, procedure_size, word_size, epsilon, dropout)\n",
    "        # Bidirectional process-level RNN\n",
    "        self.process_rnn = nn.LSTM(\n",
    "            2 * hidden_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.linear_ = nn.Linear(2 * hidden_size, 2 * word_att_size)\n",
    "        nn.init.xavier_uniform_(self.linear_.weight)\n",
    "        self.tanh_ = nn.Tanh()\n",
    "        self.softmax_ = nn.Softmax(dim=1)\n",
    "        self.u_a = nn.Parameter(torch.Tensor(2 * hidden_size, 1))\n",
    "        nn.init.xavier_uniform_(self.u_a)\n",
    "        \n",
    "        self.epsilon = epsilon #1e-7\n",
    "\n",
    "    def forward(self, procedure, process_mask, procedure_mask):\n",
    "        procedure_vector = self.procedure_attention(procedure, procedure_mask)\n",
    "        \n",
    "        procedure_vector = self.dropout(procedure_vector)\n",
    "        \n",
    "        rnn_out, _ = self.process_rnn(procedure_vector)  # (16,28,128)\n",
    "\n",
    "        h = self.tanh_(self.linear_(rnn_out))  # h = tanh(Wx+y)\n",
    "        dot = torch.matmul(h, self.u_a)\n",
    "        exp_ = torch.exp(dot)\n",
    "\n",
    "        # masking\n",
    "        exp_ = exp_ * process_mask  # (16,28,1)*(16,28,1)\n",
    "\n",
    "        exp_sum = torch.sum(exp_, dim=1)  # (16,1)\n",
    "        exp_sum += self.epsilon\n",
    "        \n",
    "        x_dim = exp_sum.size()[0]\n",
    "        y_dim = exp_sum.size()[1]\n",
    "        exp_sum_add_dim = exp_sum.view(x_dim, y_dim, 1)  # (16,1,1)\n",
    "\n",
    "        alpha = torch.div(exp_, exp_sum_add_dim)  # (16,28,1)\n",
    "        procedure_attention_vector = torch.mul(rnn_out,alpha) #(16,28,128)        \n",
    "        process_vector = torch.sum(procedure_attention_vector,dim=1) #(16,128)\n",
    "        \n",
    "        return process_vector,procedure_attention_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.752556Z",
     "start_time": "2020-10-25T07:15:07.434Z"
    }
   },
   "outputs": [],
   "source": [
    "class HierarchialAttentionNetwork(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, word_att_size, procedure_size, word_size, epsilon, dropout):\n",
    "        super(HierarchialAttentionNetwork, self).__init__()\n",
    "        self.process_attention = ProcessAttention(\n",
    "            vocab_size, emb_size, hidden_size, word_att_size, procedure_size, word_size, epsilon, dropout)\n",
    "        # Regression\n",
    "        self.regression_linear = nn.Linear(2 * hidden_size, 1)\n",
    "        nn.init.xavier_uniform_(self.regression_linear.weight)\n",
    "\n",
    "    def forward(self, process, process_mask, procedure_mask):\n",
    "        process_vector,procedure_attention_vector = self.process_attention(\n",
    "            process, process_mask, procedure_mask)\n",
    "        output = self.regression_linear(process_vector)\n",
    "        output = output.view(-1)\n",
    "\n",
    "        return output,procedure_attention_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化,損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.753396Z",
     "start_time": "2020-10-25T07:15:07.444Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word_index_dic)\n",
    "emb_size = size #200\n",
    "hidden_size = 64\n",
    "word_att_size = 64\n",
    "dropout=DROPOUT\n",
    "batch_size=BATCH_SIZE\n",
    "procedure_size=max_turn\n",
    "word_size=max_len\n",
    "epsilon = 1e-7\n",
    "lr = 1e-3\n",
    "epochs = EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データローダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.754240Z",
     "start_time": "2020-10-25T07:15:07.448Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)#,worker_init_fn=worker_init_fn)\n",
    "\n",
    "dev_loader = torch.utils.data.DataLoader(dataset_dev, batch_size=BATCH_SIZE, shuffle=False, num_workers=4,worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.755039Z",
     "start_time": "2020-10-25T07:15:07.452Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_loader,model,criterion,optimizer,train_total_loss):\n",
    "    model.train()\n",
    "    procedure_attention_vectors_list = []\n",
    "    for i,batch in enumerate(train_loader):\n",
    " \n",
    "        #cpu,gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        train_processes,train_process_mask,train_procedure_mask,train_labels = batch\n",
    "        \n",
    "        #Forward prop\n",
    "        pred_y,procedure_attention_vector = model(train_processes,train_process_mask, train_procedure_mask)\n",
    "\n",
    "        #Loss\n",
    "        loss = criterion(pred_y,train_labels)\n",
    "        \n",
    "        #Back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update\n",
    "        optimizer.step()\n",
    "\n",
    "        #Accumulated Loss\n",
    "        train_total_loss += float(loss)\n",
    "  \n",
    "        procedure_attention_vector_list = procedure_attention_vector.to('cpu').detach().numpy().copy().tolist()\n",
    "        procedure_attention_vectors_list.extend(procedure_attention_vector_list)\n",
    "    \n",
    "    return train_total_loss,procedure_attention_vectors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.755876Z",
     "start_time": "2020-10-25T07:15:07.457Z"
    }
   },
   "outputs": [],
   "source": [
    "def dev(dev_loader, model, criterion, dev_total_loss):\n",
    "    model.eval()\n",
    "    pred_dev_list = []\n",
    "    for i, batch in enumerate(dev_loader):\n",
    "\n",
    "        #cpu,gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        dev_processes,dev_process_mask,dev_procedure_mask, dev_labels = batch\n",
    "        \n",
    "        pred_y,_ = model(dev_processes,dev_process_mask, dev_procedure_mask)\n",
    "\n",
    "        loss = criterion(pred_y, dev_labels)\n",
    "               \n",
    "        dev_total_loss += float(loss)\n",
    "        \n",
    "        pred_y_list = pred_y.to('cpu').detach().numpy().copy().tolist()\n",
    "        pred_dev_list.extend(pred_y_list)\n",
    "\n",
    "    return dev_total_loss,pred_dev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.756742Z",
     "start_time": "2020-10-25T07:15:07.461Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch_len = len(train_loader)\n",
    "dev_batch_len = len(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.757583Z",
     "start_time": "2020-10-25T07:15:07.466Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_batch_len,dev_batch_len,test_batch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.758371Z",
     "start_time": "2020-10-25T07:15:07.469Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.state_dict()['process_attention.u_a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.759240Z",
     "start_time": "2020-10-25T07:15:07.476Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_procedure_to_process(log_time_series,max_turn_list):\n",
    "    process_log_time_list = []\n",
    "    \n",
    "    count = 0\n",
    "    d = deque(max_turn_list)\n",
    "    #最後のpopが処理されるためにappend\n",
    "    d.append(0)\n",
    "    #divideは各手順の最大手順数\n",
    "    max_turn = d.popleft()\n",
    "    \n",
    "    for log_time in log_time_series:\n",
    "        count += 1\n",
    "        if max_turn[0] == count:\n",
    "            process_log_time_list.append(log_time)\n",
    "            count = 0\n",
    "            max_turn = d.popleft()\n",
    "            \n",
    "    return process_log_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.760050Z",
     "start_time": "2020-10-25T07:15:07.479Z"
    }
   },
   "outputs": [],
   "source": [
    "time_dev_list = df_id_process_time_turn_divide_time_dev['time'].tolist()\n",
    "time_dev_list = time_procedure_to_process(time_dev_list,max_turn_dev_list)\n",
    "a1=(math.log(5)+math.log(10))/2\n",
    "a2=(math.log(10)+math.log(15))/2\n",
    "a3=(math.log(15)+math.log(30))/2\n",
    "a4=(math.log(30)+math.log(60))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.760840Z",
     "start_time": "2020-10-25T07:15:07.483Z"
    }
   },
   "outputs": [],
   "source": [
    "def strict_acc(pred_dev):\n",
    "    c5 = 0\n",
    "    c10 = 0\n",
    "    c15 = 0\n",
    "    c30 = 0\n",
    "    c60 = 0\n",
    "    for ans_time, pred_time in zip(time_dev_list, pred_dev):\n",
    "        if ans_time == 5:\n",
    "            if pred_time <= a1:\n",
    "                c5 += 1\n",
    "        elif ans_time == 10:\n",
    "            if a1 < pred_time <= a2:\n",
    "                c10 += 1\n",
    "        elif ans_time == 15:\n",
    "            if a2 < pred_time <= a3:\n",
    "                c15 += 1\n",
    "        elif ans_time == 30:\n",
    "            if a3 < pred_time <= a4:\n",
    "                c30 += 1\n",
    "        elif ans_time == 60:\n",
    "            if a4 < pred_time:\n",
    "                c60 += 1\n",
    " \n",
    "    return (c5+c10+c15+c30+c60)/len(pred_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T07:15:09.761751Z",
     "start_time": "2020-10-25T07:15:07.487Z"
    }
   },
   "outputs": [],
   "source": [
    "max_ACC = 0\n",
    "best_epoch = 1\n",
    "save_path = '/hoge/hoge.pth'\n",
    "torch.manual_seed(1)\n",
    "seed(1)\n",
    "model = HierarchialAttentionNetwork(vocab_size=vocab_size+1,\n",
    "                                    emb_size=emb_size,\n",
    "                                    hidden_size=hidden_size,\n",
    "                                    word_att_size=word_att_size,\n",
    "                                    procedure_size=procedure_size,\n",
    "                                    word_size=word_size,\n",
    "                                    epsilon=epsilon,\n",
    "                                    dropout=dropout)\n",
    "\n",
    "model.process_attention.procedure_attention.init_embeddings(embedding_matrix)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(params=filter(\n",
    "    lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_total_loss = 0\n",
    "    dev_total_loss = 0\n",
    "    print('###########')\n",
    "    train_loss_total, _ = train(\n",
    "        train_loader=train_loader,\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        train_total_loss=train_total_loss\n",
    "    )\n",
    "\n",
    "    dev_loss_total,pred_dev_list = dev(\n",
    "        dev_loader=dev_loader,\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        dev_total_loss=dev_total_loss\n",
    "    )\n",
    "\n",
    "    acc_dev = strict_acc(pred_dev_list)\n",
    "    \n",
    "    train_loss = train_loss_total/train_batch_len\n",
    "    dev_loss = dev_loss_total/dev_batch_len\n",
    "    print('%d回目' % (epoch+1))\n",
    "    print('train_loss:%f\\ndev_loss:%f\\nacc_dev%f\\n' %\n",
    "          (train_loss, dev_loss,acc_dev))\n",
    "\n",
    "    if max_ACC < acc_dev:\n",
    "        max_ACC = acc_dev\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            save_path\n",
    "        )\n",
    "    print('%d回目 max_ACC:%f' % (best_epoch, max_ACC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
